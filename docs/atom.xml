<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Explorations in ML</title>
 <link href="https://tensor.blog/atom.xml" rel="self"/>
 <link href="https://tensor.blog/"/>
 <updated>2021-07-19T19:04:49-07:00</updated>
 <id>https://tensor.blog</id>
 <author>
   <name>Il Jae Lee</name>
   <email>agiantwhale@gmail.com</email>
 </author>

 
 <entry>
   <title>Talking to myself using GPT</title>
   <link href="https://tensor.blog/2021/07/14/jaegpt/"/>
   <updated>2021-07-14T00:00:00-07:00</updated>
   <id>https://tensor.blog/2021/07/14/jaegpt</id>
   <content type="html">&lt;p&gt;Transformer &amp;amp; attention models are all the hype in the machine learning community recently, so I took sometime to learn about them. As a fun project, I’ve decided to build a virtual version of myself (thanks to trove of dataset from Facebook messenger export).&lt;/p&gt;

&lt;h2 id=&quot;data-preparation&quot;&gt;Data preparation&lt;/h2&gt;
&lt;p&gt;The training data was prepared through &lt;a href=&quot;https://www.facebook.com/dyi/&quot;&gt;downloading my entire Facebook chat history&lt;/a&gt;, and using a &lt;a href=&quot;https://github.com/agiantwhale/jaegpt/blob/master/build_dataset.py&quot;&gt;parsing script&lt;/a&gt; I wrote. There’s a couple of gotchas when it comes to parsing Facebook messages data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ignore chat threads where most of the language is non-English (Korean is my first language).&lt;/li&gt;
  &lt;li&gt;Remove automated messages (Eg: &lt;em&gt;Words With Friends&lt;/em&gt; game requests).&lt;/li&gt;
  &lt;li&gt;Combine consecutive messages into a single sentence.&lt;/li&gt;
  &lt;li&gt;Set a threshold to yield a new context (I’ve chosen this as 50th percentile of message time delta).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Overall, the preparation pipeline looks as follows:&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Data Design&quot; src=&quot;/assets/080ffd-9b97b12b201cad3f403a9460b25c753e200c1f8277f46ba1ef74f2ec7aad857f.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The context of the model is preceding 4 messages before my reply. 3 distractors are chosen from the sent replies in the current chat for the supervision task. I haven’t investigated the effects of these two parameter choices – tuning these context and distractor parameters could be an interesting study.&lt;/p&gt;

&lt;p&gt;The final dataset yields 29192 lines and is 11MB. I’ve split as 25000 lines as training set and the rest 4192 lines as the validation set. This is a fraction of the amount of data the baseline model was trained on (&lt;a href=&quot;https://github.com/microsoft/DialoGPT&quot;&gt;DialoGPT was trained on 147M multi-turn dialogue from Reddit&lt;/a&gt;). Regardless, I found that I was able to get reasonable results with these small datasets.&lt;/p&gt;

&lt;p&gt;Here is the final objective distribution (for a reply of length &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-79f87014553f5184b3cd09f19cd17710.png&quot; /&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-7dbbb6c1c1e864356562ddd86f3865a1.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-architecture&quot;&gt;Model architecture&lt;/h2&gt;
&lt;p&gt;The architecture is taken directly from the &lt;a href=&quot;https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313&quot;&gt;HuggingFace’s ConvAI2 (NeurIPS 2018) winning model&lt;/a&gt;. The language modeling head is making the actual token predictions, with an extra next sentence classification head added on to the hidden states of the last token to discriminate between the correct reply and a negatively sampled reply. Refer to the linked blogpost and the code for details – the transformer network (and attention module) is a fascinating piece of work that deserves close… &lt;em&gt;attention&lt;/em&gt;. For the sake of this post, you can think of the attention module as learning a masking function that focuses on each word in a given sentence (in a &lt;em&gt;fill-in-the-blank&lt;/em&gt; manner).&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Model Design&quot; src=&quot;/assets/3252d5-2893c45230d669469248a31c517076502b4e43ccd1f7032790e2d3014b1f9d56.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It seems the discriminator head is designed to act as a weak supervision function to aid language modeling task (through cross learning), but &lt;strong&gt;I didn’t notice any noticable improvements to the main LM task without it.&lt;/strong&gt; More details in the following sections.&lt;/p&gt;

&lt;h2 id=&quot;training-implementation&quot;&gt;Training implementation&lt;/h2&gt;
&lt;p&gt;I’m relying on HuggingFace’s Transformer library to train the model on Google Colab’s TPUs. I ran into several problems, which I mostly fixed by copy-paste engineering and customizing to suit my needs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training on TPU (using &lt;a href=&quot;https://github.com/pytorch/xla&quot;&gt;pytorch/xla&lt;/a&gt;) requires fixed tensor sizes for speed up. This requires some additional care on preprocessing the data part (see block size optimization on parameter tuning section below). I assume this is due to TPU internally optimizing the memory layout.&lt;/li&gt;
  &lt;li&gt;HuggingFace’s Trainer (as of v4.8.2) does not support exporting multiple losses. The final optimization loss is the weighted sum of two tasks: language modeling and next sentence classification, but for final evaluation we only care about the language modeling task. A quick hack to report all three loss is in the code implementation &lt;a href=&quot;https://github.com/agiantwhale/jaegpt/blob/master/fbgpt/trainer.py&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;DialoGPT was trained without using token IDs, as a special boolean mask to indicate whether a sentence is a reply or not.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following sections describe the parameter tuning explorations.&lt;/p&gt;

&lt;h3 id=&quot;block-size&quot;&gt;Block size&lt;/h3&gt;
&lt;p&gt;This is to resolve the fixed tensor requirement with the TPU above. I wrote a script to calculate percentage of training rows that go above limit at each tokenization step. From the chart below, it seems we get a 99% yield with block size of &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-e0afb0c7a5e6c6ec867e9bbea08b6b10.png&quot; /&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Block size and final data yield&quot; src=&quot;/assets/40c68c-af8a1995113ef38010ca5d76bbcdabff1d848cb9fd7690e177884883b9de0343.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’ve updated the data processing step to pad the data to become a fixed width of 128 and ignore rows that overflow – we are good to go.&lt;/p&gt;

&lt;h3 id=&quot;epoch&quot;&gt;Epoch&lt;/h3&gt;
&lt;p&gt;I kicked off an exploratory run with epoch of 4 to see if multi-epoch training is even reasonable. Small dataset, large model size and sparse tokens seems like a recipe for overfitting, so I chose a batch size of 1 per TPU (which gives us an update batch size of 8, as there are 8 TPU cores). Next sentence prediction task was not used in this run.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Eval vs Train Loss, Epoch&quot; src=&quot;/assets/6e670d-583ed536591dd313f68ac6d8e73413cb1064e2ce622e611d77ac6622e997c067.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We seem to overfit after 1 epoch, with eval loss increasing after 2 epoch.&lt;/p&gt;

&lt;h3 id=&quot;task-weight-exploration&quot;&gt;Task weight exploration&lt;/h3&gt;

&lt;p&gt;For a baseline, below is the entropy of a background predictors that generate a random choice for the two tasks. The DialoGPT tokenizer contains 50257 tokens, and we choose 3 distractors for the next sentence prediction tasks.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-7b1b14389b8ed1593e58412ea7b2d214.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The background entropy for language modeling task is 7.8 times higher than next sentence prediction! A 50% reduction in the classification task would be considered only a 7% reduction in the language modeling task in the final loss function.&lt;/p&gt;

&lt;p&gt;The final loss function is formulaized as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-d91e79dee13c6be43f63c0e6011afb9e.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To verify the potential improvements, I tuned the &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-c08a7b5eb987e4198f55df3047c97bf7.png&quot; /&gt; in the combined loss to the following values. Reported metrics are eval metrics.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-c08a7b5eb987e4198f55df3047c97bf7.png&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-480ff5082f729e253113a042a6c9bbac.png&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-810c648c5a616153702c17cba3428550.png&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-6c9c382af2e89e83ff13a592ab81e473.png&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-18fb601c4ccd970049908cca46af8ff2.png&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-51e1008cf65efc66bd2ed2b87fc292f3.png&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;1.819&lt;/td&gt;
      &lt;td&gt;1.312&lt;/td&gt;
      &lt;td&gt;7.814&lt;/td&gt;
      &lt;td&gt;0.722&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;0.0014&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;1.328&lt;/td&gt;
      &lt;td&gt;0.958&lt;/td&gt;
      &lt;td&gt;5.229&lt;/td&gt;
      &lt;td&gt;0.483&lt;/td&gt;
      &lt;td&gt;0.0012&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;1.063&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;0.767&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;4.503&lt;/td&gt;
      &lt;td&gt;0.415&lt;/td&gt;
      &lt;td&gt;0.0002&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0.1&lt;/td&gt;
      &lt;td&gt;1.325&lt;/td&gt;
      &lt;td&gt;0.956&lt;/td&gt;
      &lt;td&gt;4.365&lt;/td&gt;
      &lt;td&gt;0.403&lt;/td&gt;
      &lt;td&gt;0.0002&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0.01&lt;/td&gt;
      &lt;td&gt;1.386&lt;/td&gt;
      &lt;td&gt;0.999&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;4.361&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;0.402&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;0.0001&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;And their corresponding learning curves:&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Eval LM Loss&quot; src=&quot;/assets/58abfa-fe7641420f092273b283e4fb725aa6a2ce4373f40f074c3a528a546a67db6575.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the supervision tasks shows minimal improvement to the main LM loss; rather makes it worse.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Eval Accuracy&quot; src=&quot;/assets/5e22d3-4ade7ea546028b192758d1d1f095de3973c0fbe05b69b7d070751e3ca8200979.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In constract to &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-6c9c382af2e89e83ff13a592ab81e473.png&quot; /&gt;, the inclusion of supervision tasks increase the LM modeling accuracy. However this isn’t a good metric to optimize for, as we will be using beam search to generate responses through sampling; learning an accurate distribution of next token is more important than predicting the most likely token.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Eval MC Loss&quot; src=&quot;/assets/da7491-1bfc19dfd9b57040cca9ca44bba2649b0091d3329688f372d58054b6eafd497f.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Increasing the &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-c08a7b5eb987e4198f55df3047c97bf7.png&quot; /&gt; parameter does not result in linear increase to MC loss, with &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-f6fbad6a2333abe8d09954cff4137205.png&quot; /&gt; showing the best result. In fact, a multiplier of 100 shows a worse result than random guess! I couldn’t think of a reasonable explanation for this; my guess is it has to do with steep gradient magnitudes with higher &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-c08a7b5eb987e4198f55df3047c97bf7.png&quot; /&gt;; plotting magnitude of gradient might give us a better idea here.&lt;/p&gt;

&lt;h3 id=&quot;bayes-hyperparameter-optimization&quot;&gt;Bayes hyperparameter optimization&lt;/h3&gt;
&lt;p&gt;We did some initial exploration of model architectures; now let’s systematically explore the entire search space to get the best candidate. To do this, we utilize &lt;a href=&quot;https://github.com/wandb/client/tree/master/wandb/sweeps&quot;&gt;Weights &amp;amp; Biases’ excellent sweep utility&lt;/a&gt;, with the &lt;a href=&quot;https://github.com/agiantwhale/jaegpt/blob/master/search.yml&quot;&gt;config&lt;/a&gt; tuned to run various configurations. The sweep algorithm is very simple, it fits a gaussian process regressor on parameter and samples from the trained distribution.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Sweep Results&quot; src=&quot;/assets/298c25-e79449652157108550e94ada12b69cb3b360c8fda7288f2ea1c994339c195fd1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The results of the runs are listed below:&lt;/p&gt;

&lt;table&gt;
  
    
    &lt;tr&gt;
      
        &lt;th&gt;Learning Rate&lt;/th&gt;
      
        &lt;th&gt;MC Task Weight&lt;/th&gt;
      
        &lt;th&gt;Epoch&lt;/th&gt;
      
        &lt;th&gt;Batch Size&lt;/th&gt;
      
        &lt;th&gt;MC Loss&lt;/th&gt;
      
        &lt;th&gt;LM Loss&lt;/th&gt;
      
    &lt;/tr&gt;
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        5.18e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0493938
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.2804
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3287
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        4.15e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0475979
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.2951
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3339
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        4.41e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.026687
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3102
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3351
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        6.16e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0051356
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3154
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3364
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        4.66e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0073607
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3241
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3367
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        2.96e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0223147
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        4
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.319
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3451
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        5.86e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0147082
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        4
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.2968
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3544
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        5.46e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0419673
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        1
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        4
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3124
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3571
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        0.0001275
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0195402
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        1
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3133
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3706
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        8.3e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0365972
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        1
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3181
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.3762
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        7.55e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0220401
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        3
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.2633
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.4274
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        8.66e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.022435
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        3
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.2549
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.4661
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        9.43e-05
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0229404
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        3
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.262
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        4.4974
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        0.0008321
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.011086
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        1
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        4
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3276
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        5.1287
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        0.0014851
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        0.0079413
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        1
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        4
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.3417
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        5.9006
    &lt;/td&gt;&lt;/tr&gt;

  
    

    &lt;tr class=&quot;row1&quot;&gt;
&lt;td class=&quot;col1&quot;&gt;
        0.0001262
    &lt;/td&gt;&lt;td class=&quot;col2&quot;&gt;
        46.8726004
    &lt;/td&gt;&lt;td class=&quot;col3&quot;&gt;
        2
    &lt;/td&gt;&lt;td class=&quot;col4&quot;&gt;
        8
    &lt;/td&gt;&lt;td class=&quot;col5&quot;&gt;
        1.334
    &lt;/td&gt;&lt;td class=&quot;col6&quot;&gt;
        7.0459
    &lt;/td&gt;&lt;/tr&gt;

  
&lt;/table&gt;

&lt;p&gt;I’ve kicked off a final training run with all data with the following parameters:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-afeb466cb4ee4edf8f6319eee1fb93a8.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-24bd77d4a18ce9f7dc612e1f5f62d506.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-b67d941e3161239fe32db79dd933e200.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-5f7a43e67fa4762254dbdb150b39e8a0.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conversation-examples&quot;&gt;Conversation examples&lt;/h2&gt;
&lt;p&gt;I’ve generated some samples using the &lt;a href=&quot;https://github.com/agiantwhale/jaegpt/blob/master/interact.py&quot;&gt;generator script in the repository&lt;/a&gt;. It relies on HuggingFace’s implementation of beam search, where a token is sampled from the predicted distribution of tokens (with previous tokens as the prior). After some trial and error I’ve arrived at &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-1e1e36d25130ce0cc23586ce5aa776f9.png&quot; /&gt; (filter out tokens where probability is &amp;lt; 0.25, and choose top 100 tokens).&lt;/p&gt;

&lt;h3 id=&quot;jae-gpt-on-his-hobbies&quot;&gt;Jae-GPT on his hobbies.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; What hobbies do you enjoy in your free time
JaeGPT: I'm not sure what I enjoy in free time, but I'm not really into hip hop or



&amp;gt;&amp;gt;&amp;gt; Are you actively working on developing your hobbies
JaeGPT: I like to listen to music and play video games, but also like to play video game games and



&amp;gt;&amp;gt;&amp;gt; Which video games?
JaeGPT: I'm working on a game called Minecraft that's pretty fun and addictive, but it's not optimized



&amp;gt;&amp;gt;&amp;gt; You're trying to create Minecraft
JaeGPT: I don't think Minecraft is a good idea for a first time user. It's a lot of


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;jae-gpt-on-collecting-wrist-watches&quot;&gt;Jae-GPT on collecting wrist watches.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Do you like collecting wristwatches
JaeGPT: I don't like watches but I like watches that look cool and I like the design of them and



&amp;gt;&amp;gt;&amp;gt; Which watch do you think looks the coolest
JaeGPT: I like watches with a nice design and a good finish but I don't really like watches as a



&amp;gt;&amp;gt;&amp;gt; as a tool?
JaeGPT: I think it looks pretty cool but I think it's too much work for me to wear everyday lol



&amp;gt;&amp;gt;&amp;gt; I like to wear my nomos everyday
JaeGPT: i don't like watches that's too formal but i like watches for everyday wear so i'll probably



&amp;gt;&amp;gt;&amp;gt; wear an apple watch?
JaeGPT: I'm thinking of buying a watch with a strap that's more comfortable to wear on the wrist and


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;jae-gpt-on-discussing-the-stock-market&quot;&gt;Jae-GPT on discussing the stock market.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Should I buy some options on Robinhood
JaeGPT: What's Robinhood? I'm not sure if it's a mutual fund or not lololol



&amp;gt;&amp;gt;&amp;gt; It's a brokerage
JaeGPT: I'm not a big investor in Robinhood but I'm a big fan of the company and I



&amp;gt;&amp;gt;&amp;gt; Are you bullish or bearish on Robinhood
JaeGPT: I think I'm bullish on Robin hood but I think I'll be bullish on Amazon and Google too



&amp;gt;&amp;gt;&amp;gt; So you like all the tech stocks
JaeGPT: I'm bullish for Robinhood too but I don't think I can get into FB or Google lol



&amp;gt;&amp;gt;&amp;gt; But you work for Facebook
JaeGPT: I think you can get a job at Google or Amazon too if you're a tech company and you


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;jae-gpt-on-wealth-accumulation&quot;&gt;Jae-GPT on wealth accumulation.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; What kind of life do you want to live?
JaeGPT: I want to be a billionaire but I don't want to go back to school and live a life



&amp;gt;&amp;gt;&amp;gt; It's not easy to become a billionaire.
JaeGPT: I'm not sure if I can do that But I'm willing to try my best to make it



&amp;gt;&amp;gt;&amp;gt; Get rich or die trying
JaeGPT: I want a billionaire to live a long life so I can be a millionaire again and live the rest



&amp;gt;&amp;gt;&amp;gt; You're going to become a millionaire from a billionaire?
JaeGPT: I'm going to be a billionaire from a millionaire I'm going into a billionaire I'm not going


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;jae-gpt-on-living-in-korea&quot;&gt;Jae-GPT on living in Korea.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Would you ever move back to Korea?
JaeGPT: I'm not sure, I'm not a big fan of the culture there, I think I'll



&amp;gt;&amp;gt;&amp;gt; What don't you like about the culture?
JaeGPT: The culture is pretty chill, but I'm kinda scared of the people I met there lol. I



&amp;gt;&amp;gt;&amp;gt; You are scared of Koreans?
JaeGPT: I'm scared of Asians too. I'm scared to be interviewed there lolololol. I



&amp;gt;&amp;gt;&amp;gt; That's interesting since you are Korean.
JaeGPT: I don't think I'll be applying to any of the big tech companies in Korea lol. They


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;jae-gpt-on-his-delusions-on-the-housing-market&quot;&gt;Jae-GPT on his delusions on the housing market.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Got any good stock picks?
JaeGPT: I'm thinking of buying a house in SF for $200, but I'm not sure yet.



&amp;gt;&amp;gt;&amp;gt; Wow! That's an amazing deal. Where?
JaeGPT: San Mateo! It's a pretty small place but I think it's worth it. I'm



&amp;gt;&amp;gt;&amp;gt; $200! Are you sure it's not a cardboard box on the streets?
JaeGPT: I'm not too sure, I'll ask my friend who's living in SF and ask if he



&amp;gt;&amp;gt;&amp;gt; You should do more background research.
JaeGPT: I've been thinking about getting a job at a startup in SF for the past couple of years.



&amp;gt;&amp;gt;&amp;gt; Are you sure that will pay for the house?
JaeGPT: I'm thinking of moving to SF, but I'm not sure if I can get a job there


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;jae-gpt-on-gaming-pc&quot;&gt;Jae-GPT on gaming PC.&lt;/h3&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Is a gaming PC worth it
JaeGPT: I don't think so But I'm not sure if it's worth it to buy a gaming computer



&amp;gt;&amp;gt;&amp;gt; But you can play TF2 on full options
JaeGPT: I'm not buying a gaming pc for gaming lol I'm buying a laptop for gaming and gaming lol



&amp;gt;&amp;gt;&amp;gt; Laptop for gaming sucks
JaeGPT: I have a gaming PC and I can play tf2 on it lol I can't play TF1


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Intuitive Explanation of Group LASSO Regularization for Neural Network Interpretability</title>
   <link href="https://tensor.blog/2020/08/03/group-lasso/"/>
   <updated>2020-08-03T00:00:00-07:00</updated>
   <id>https://tensor.blog/2020/08/03/group-lasso</id>
   <content type="html">&lt;p&gt;Neural networks are often referred to as a black box model because of its lack of interpretability. Most of a network’s operations occur in the hidden layers and latent space. As a result, tracing important features in a dataset is not an easy task, especially when the number of features is large. This is often a limiting factor in applying neural networks in fields where explainability is not only favored, but crucial (such as medical diagnostics or finance).&lt;/p&gt;

&lt;p&gt;Through this entry, we hope to examine the application of the group LASSO regularization for solving the problems described above.&lt;/p&gt;

&lt;h2 id=&quot;what-is-ridge-and-lasso-regularization&quot;&gt;What is ridge and LASSO regularization?&lt;/h2&gt;
&lt;p&gt;The loss function of ridge regression can be defined as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-b832c44e16abdcd71034eb8a69f73d4f.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;while loss function of LASSO regression can be defined as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-c706b7933e2425517886943a7c4855dd.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above loss functions can be broken down into&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Predicted output: &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-1f625f17552856d6463fcac3c32101b3.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Regularization term
    &lt;ul&gt;
      &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-c343adb0c473016c19f48b35e9ee1923.png&quot; /&gt; for LASSO&lt;/li&gt;
      &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-fa17a9b380844ff87dc1095a6f843f17.png&quot; /&gt; for ridge&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Comparison of the two regularization terms shows the intuition behind LASSO regression’s better interpretability characteristics. From a Big-O standpoint, &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-f037b2a8bf7aa27b03b3a16f052acd06.png&quot; /&gt;. The penalty for having one skewed large value is much greater for ridge regression. Ridge regularization aims to reduce variance between the coefficients, therefore driving all features down to zero.&lt;/p&gt;

&lt;p&gt;LASSO regularization, on the other hand, will set some feature’s coefficients to zero values when deemed necessary, effectively removing them. We then can compare non-zero coefficients to determine the importance of the features.&lt;/p&gt;

&lt;h2 id=&quot;what-is-group-lasso-regularization&quot;&gt;What is group LASSO regularization?&lt;/h2&gt;
&lt;p&gt;From the above example, we observe how LASSO regularization can help with the interpretability of the model. But some problems may benefit from a group of features used together, especially when incorporating domain knowledge into the model.&lt;/p&gt;

&lt;p&gt;Group LASSO attempts to solve this problem by separating the entire feature set into separate feature groups. The regularization function can be written as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-982f81b039618d09108f899cf26f46c5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-10afdb7058d58d26e17462afab5184e1.png&quot; /&gt; denotes the size of the group.&lt;/li&gt;
  &lt;li&gt;&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-1260e71e0fc41670c2fe966156d4aa01.png&quot; /&gt; denotes the L2-norm of the feature group &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-4322e011bfdf0bfdc4c27891ff3dfc61.png&quot; /&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s take a closer look at the regularization term &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-efcb5f9f42d3fc2659fff45d27825d09.png&quot; /&gt;.&lt;/p&gt;

&lt;p&gt;Note that &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-04f7d616922df5bee90be4315df5bd74.png&quot; /&gt;, and we for some &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-3fc4979464ed4d76e333e61e3bd92615.png&quot; /&gt; that satisfies &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-d9cbfed9c4e18f1438b295b5ed388b2c.png&quot; /&gt;, we could effectively rewrite the equation as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-502db40ff96a3f8501db90bbd383a2f1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, we have effectively reduced the regularization to LASSO regularization on the inter-group level.&lt;/p&gt;

&lt;p&gt;Similarly, let’s take a look an subgroup. Expanding the term for some group with cardinality &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-cf56f66cf006f2f909a26e2840fb3197.png&quot; /&gt;, the regularization term can be expressed as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-ef2df46f53bb8711bf2f93489981cbfc.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here, we have effectively reduced the regularization to ridge regularization on the intra-group level.&lt;/p&gt;

&lt;p&gt;We build on the intuition that while it cannot select certain features within the same group, because of it’s LASSO-like nature between feature groups, the model will zero-out entirety of certain coefficient groups.&lt;/p&gt;

&lt;p&gt;Additionally, note the two following characteristics:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;When &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-b509903172b539c1855c10cb08e2b0a9.png&quot; /&gt;, the regularization term essentially becomes a LASSO (L1) regularization.&lt;/li&gt;
  &lt;li&gt;When &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-67dc231cbb67be814d1770bc40e27f66.png&quot; /&gt;, the regularization term essentially becomes a ridge (L2) regularization.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-can-we-adapt-group-lasso-for-neural-networks&quot;&gt;How can we adapt group LASSO for neural networks?&lt;/h2&gt;
&lt;p&gt;Up to now, the application of regularization terms have been on linear regression methods where each features are assigned a single coefficient weight. Now, we will take a look at a neural network, specifically on the connections between the first two layer of the network, where each individual features have multiple weights associated to the next layer.&lt;/p&gt;

&lt;p&gt;To visualize this, say we have a small neural network with one hidden layer.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-676b7e3e942012b08f4761cb52d6598c.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In order for the above feature selection to work, we will need to zero out the weights connected for all of feature &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-63ac1428cb664318e538521970b9c31d.png&quot; /&gt; (marked in red).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-6380075deae1b69a4865b8777a069e99.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, the weights associated with each of the neurons becomes becomes a group of their own. Let &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-588e7585b44191d96d5d21a3b0f9d8af.png&quot; /&gt; and &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-f78c1d7bf8cdc1fa8475ee763ebaa13f.png&quot; /&gt; denote the weight vectors for input features &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-a61fcbe9f079dadb08038189261d695e.png&quot; /&gt; and &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-63ac1428cb664318e538521970b9c31d.png&quot; /&gt; (&lt;img class=&quot;inline&quot; src=&quot;/latex/latex-f78c1d7bf8cdc1fa8475ee763ebaa13f.png&quot; /&gt; weights would be marked in red above). We can adapt the group LASSO regularization formulation as&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-ef01b74a4d23c0555bc00ca85c7fcbaa.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-ad4c0ceaad058aef6ccf3e724ca12b9a.png&quot; /&gt; denotes the loss function and &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-3035883f6531462455e562d330180152.png&quot; /&gt; denotes the full-connected weights to feature &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-7bdce1f20016bc5e7197ccbbb0a86fab.png&quot; /&gt;. Since we have two input features, the regularization term would also expand to&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;/latex/latex-987cc3e980a19372984ddcd977ea3a9a.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We have essentially derived the Group level lasso regularization on each of the individual features, with the weights corresponding to each feature in a group. We can continue to build on the intuition from the Group LASSO.&lt;/p&gt;

&lt;p&gt;While each individual weights inside a weight group will not differ in terms of convergence to zero (all elements of &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-588e7585b44191d96d5d21a3b0f9d8af.png&quot; /&gt;, &lt;img class=&quot;inline&quot; src=&quot;/latex/latex-f78c1d7bf8cdc1fa8475ee763ebaa13f.png&quot; /&gt; will either be zero or non-zero), the non-continuous nature of the l2 norm for individual features will introduce sparsity and converge entire feature weights to 0.&lt;/p&gt;

&lt;p&gt;From here, it’s trivial to apply the same technique to regularizing hidden layers to introduce further sparsity to the model and improve model capacity or prune unneeded connections.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://icml.cc/Conferences/2010/papers/473.pdf&quot;&gt;Yang, Haiqin et al. “Online Learning for Group Lasso.” &lt;em&gt;ICML&lt;/em&gt; (2010).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1607.00485&quot;&gt;Scardapane, Simone et al. “Group Sparse Regularization for Deep Neural Networks.” Neurocomputing 241 (2017): 81–89. Crossref. Web.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 

</feed>
